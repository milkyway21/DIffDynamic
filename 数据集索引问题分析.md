# 数据集索引问题分析

## 问题描述

运行采样命令时出现 `IndexError: list index out of range`：

```
python scripts/sample_diffusion.py configs/sampling.yml --data_id 5 --device cuda:0 --mode dynamic --result_path ./outputs/pocket5_samples
```

错误发生在：
```python
File "/mnt/d/DiffDynamic/datasets/pl_pair_dataset.py", line 235, in get_ori_data
    key = self.keys[idx]
IndexError: list index out of range
```

## 问题原因分析

### 根本原因

**索引不匹配问题**：`split` 文件中的索引是基于原始 `index.pkl` 的，但 LMDB 中只包含成功处理的样本。如果处理时跳过了某些样本，索引就会不匹配。

### 详细流程

1. **原始索引文件 (`index.pkl`)**
   - 包含所有原始样本的列表
   - 例如：1000 个样本，索引 0-999

2. **LMDB 处理过程 (`_process()`)**
   - 遍历 `index.pkl` 中的所有样本
   - 对于每个样本：
     - 如果 `pocket_fn is None`：跳过
     - 如果解析失败（异常）：跳过
     - 如果成功：写入 LMDB，键为 `str(i)`（i 是原始索引）
   - **结果**：LMDB 中可能只有部分样本，例如只有 100 个键（"0", "1", ..., "99"）

3. **Split 文件 (`crossdocked_pocket10_pose_split.pt`)**
   - 包含训练/验证/测试集的索引列表
   - 这些索引是基于**原始 `index.pkl`** 的
   - 例如：`test: [5, 10, 15, ..., 995]`（100 个索引）

4. **问题出现**
   - 测试集索引 5 指向原始索引 5
   - 但如果原始索引 5 在处理时被跳过，LMDB 中就没有键 "5"
   - 当 `Subset` 尝试访问 `dataset[5]` 时，`PocketLigandPairDataset` 会查找 `self.keys[5]`
   - 如果 `self.keys` 的长度小于 5，就会报错

### 可能的具体情况

**情况 1：LMDB 中的键不连续**
- 原始索引：0, 1, 2, 3, 4, 5, 6, ...
- 处理时：索引 2 和 4 被跳过
- LMDB 键：["0", "1", "3", "5", "6", ...]
- `self.keys` 列表：`[b'0', b'1', b'3', b'5', b'6', ...]`
- 当访问索引 5 时，`self.keys[5]` 实际上是原始索引 6 的数据
- 但如果 split 文件中的索引 5 指向原始索引 5，就会出错

**情况 2：LMDB 中的键数量少于 split 文件中的索引**
- 如果处理时跳过了很多样本
- LMDB 中只有 50 个键（"0" 到 "49"）
- 但 split 文件中的测试集索引包含 [5, 10, 15, ..., 995]
- 当访问索引 5 时，如果 `self.keys` 的长度小于 5，就会报错

**情况 3：索引映射错误**
- `Subset` 使用 `indices` 来索引原始数据集
- 如果 `indices[5] = 100`（原始索引 100）
- 但 `self.keys` 只有 50 个元素
- 访问 `self.keys[100]` 就会超出范围

## 诊断方法

运行诊断脚本：

```bash
python 诊断数据集问题.py
```

这个脚本会：
1. 检查 split 文件中的索引范围
2. 检查 LMDB 中的实际键
3. 找出不匹配的索引
4. 分析问题原因

## 解决方案

### 方案 1：重新生成 LMDB（推荐）

确保所有样本都能成功处理：

```bash
# 删除旧的 LMDB 文件
rm -f ./data/crossdocked_v1.1_rmsd1.0_pocket10_processed_final.lmdb

# 重新运行采样（会自动重新生成 LMDB）
python scripts/sample_diffusion.py configs/sampling.yml --data_id 0 --device cuda:0 --mode dynamic --result_path ./outputs/test
```

### 方案 2：使用实际存在的索引

先检查 LMDB 中有哪些键：

```python
import lmdb

db = lmdb.open('./data/crossdocked_v1.1_rmsd1.0_pocket10_processed_final.lmdb', readonly=True)
with db.begin() as txn:
    keys = [int(k.decode()) for k in txn.cursor().iternext(values=False)]
keys.sort()
print(f"可用的索引: {keys[:20]}...")  # 显示前20个
```

然后使用实际存在的索引进行采样。

### 方案 3：修复 split 文件

如果 LMDB 中的键是连续的（0 到 N-1），可以重新生成 split 文件：

```python
import torch

# 假设 LMDB 中有 100 个样本（索引 0-99）
total_samples = 100
indices = list(range(total_samples))

# 划分数据集（例如：80% 训练，10% 验证，10% 测试）
train_size = int(0.8 * total_samples)
val_size = int(0.1 * total_samples)

train_indices = indices[:train_size]
val_indices = indices[train_size:train_size+val_size]
test_indices = indices[train_size+val_size:]

split = {
    'train': torch.tensor(train_indices),
    'val': torch.tensor(val_indices),
    'test': torch.tensor(test_indices)
}

torch.save(split, './data/crossdocked_pocket10_pose_split_fixed.pt')
```

## 检查步骤

1. **检查 LMDB 文件是否存在**
   ```bash
   ls -lh ./data/crossdocked_v1.1_rmsd1.0_pocket10_processed_final.lmdb
   ```

2. **检查 split 文件**
   ```bash
   python -c "import torch; split = torch.load('./data/crossdocked_pocket10_pose_split.pt'); print('Keys:', list(split.keys())); [print(f'{k}: {len(v)} samples, range [{v.min()}, {v.max()}]') for k, v in split.items()]"
   ```

3. **检查原始数据路径**
   ```bash
   ls -lh ./data/crossdocked_v1.1_rmsd1.0_pocket10/
   ```

4. **运行诊断脚本**
   ```bash
   python 诊断数据集问题.py
   ```

## 常见原因

1. **数据文件缺失**：某些 PDB 或 SDF 文件不存在，导致处理时跳过
2. **数据格式错误**：某些文件格式不正确，解析失败
3. **路径问题**：数据路径配置错误，找不到文件
4. **LMDB 不完整**：处理过程中断，LMDB 文件不完整

## 预防措施

1. **确保数据完整性**：在生成 LMDB 前检查所有必需文件是否存在
2. **检查处理日志**：注意处理时跳过的样本数量
3. **验证索引匹配**：生成 LMDB 后验证 split 文件中的索引是否都在 LMDB 键范围内
4. **使用一致的版本**：确保 split 文件和 LMDB 是基于同一版本的原始数据生成的

