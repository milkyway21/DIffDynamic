# RTX 5080 (16GB显存) 采样参数优化说明

## 已优化的配置参数

### 1. `configs/sampling.yml` 已调整的参数

#### 动态采样模式 (dynamic)
- **`dynamic.large_step.batch_size`**: `32` → `16`
  - 影响：大步探索阶段同时处理的候选数量
  - 显存节省：约50%（这是影响显存最大的参数）
  
- **`dynamic.refine.n_sampling`**: `3` → `2`
  - 影响：精炼阶段对每个候选的采样次数
  - 显存节省：约33%
  
- **`dynamic.selector.top_n`**: `16` → `12`
  - 影响：从大步探索阶段选中的候选数量
  - 显存节省：约25%

### 2. 基线采样模式 (baseline) 参数调整

基线模式使用命令行参数 `--batch_size`，默认值为 `100`。对于16GB显存，建议使用：

```bash
# 推荐命令（baseline模式）
python scripts/sample_diffusion.py configs/sampling.yml \
  -i 0 --device cuda:0 --batch_size 32 \
  --mode baseline --result_path ./outputs/baseline_case0
```

**建议的batch_size值**：
- **保守设置**：`--batch_size 16-24`（适合大分子或复杂口袋）
- **推荐设置**：`--batch_size 32`（平衡速度和显存）
- **激进设置**：`--batch_size 48-64`（如果显存充足，可以尝试）

## 显存使用估算

### 动态采样模式
- **模型权重**：~2-3GB
- **大步探索阶段**：`batch_size=16` 时约 4-6GB
- **精炼阶段**：`top_n=12, n_sampling=2` 时约 2-3GB
- **峰值显存**：约 8-12GB（留有安全余量）

### 基线采样模式
- **模型权重**：~2-3GB
- **批次处理**：`batch_size=32` 时约 4-6GB
- **峰值显存**：约 6-9GB

## 进一步优化建议

### 如果仍然出现OOM（显存不足）错误：

1. **降低动态采样batch_size**：
   ```yaml
   dynamic:
     large_step:
       batch_size: 12  # 进一步降低到12
   ```

2. **降低基线模式batch_size**：
   ```bash
   --batch_size 16  # 或更小
   ```

3. **减少精炼采样次数**：
   ```yaml
   dynamic:
     refine:
       n_sampling: 1  # 从2降至1
   ```

4. **减少候选数量**：
   ```yaml
   dynamic:
     selector:
       top_n: 8  # 从12降至8
   ```

5. **使用混合精度**（如果模型支持）：
   - 在模型前向传播中使用 `torch.cuda.amp.autocast()`

### 如果显存充足，可以适当提高：

1. **提高动态采样batch_size**：
   ```yaml
   dynamic:
     large_step:
       batch_size: 20  # 可以尝试20
   ```

2. **提高基线模式batch_size**：
   ```bash
   --batch_size 48  # 或64
   ```

## 监控显存使用

运行采样时，可以在另一个终端监控显存：

```bash
# Linux
watch -n 1 nvidia-smi

# 或使用Python脚本
python -c "import torch; print(f'GPU Memory: {torch.cuda.memory_allocated()/1024**3:.2f} GB')"
```

## 当前优化配置总结

| 参数 | 原值 | 优化值 | 显存影响 |
|------|------|--------|----------|
| `dynamic.large_step.batch_size` | 32 | **16** | 高（最大影响） |
| `dynamic.refine.n_sampling` | 3 | **2** | 中 |
| `dynamic.selector.top_n` | 16 | **12** | 中 |
| `--batch_size` (baseline) | 100 | **32** (建议) | 高 |

## 使用示例

### 动态采样（已优化配置）
```bash
python scripts/sample_diffusion.py configs/sampling.yml \
  -i 0 --device cuda:0 \
  --mode dynamic --result_path ./outputs/dynamic_case0
```

### 基线采样（需要指定batch_size）
```bash
python scripts/sample_diffusion.py configs/sampling.yml \
  -i 0 --device cuda:0 --batch_size 32 \
  --mode baseline --result_path ./outputs/baseline_case0
```

## 注意事项

1. **首次运行建议**：先用较小的batch_size测试，确认不会OOM后再逐步增加
2. **不同口袋大小**：大口袋（更多原子）需要更小的batch_size
3. **模型大小**：如果使用更大的模型，需要进一步降低batch_size
4. **系统显存**：确保系统和其他程序没有占用过多显存

---

## 详细资源使用分析（基于代码流程）

### 硬件配置参考
- **CPU**: Intel Core i9-14900K (24核32线程, 3.2-5.8GHz)
- **GPU**: NVIDIA RTX 5080 (16GB GDDR7, ~40 TFLOPS FP32)
- **典型口袋**: 蛋白原子数 100-200，配体原子数 20-40

---

## 一、初始化阶段

### 1.1 配置加载和日志初始化
- **显存**: < 0.1GB（几乎无显存使用）
- **CPU**: 低（< 5%），单核，约0.1秒
- **操作**: YAML解析、日志器创建

### 1.2 模型加载
- **显存**: **2.5-3.0GB**
  - 模型权重：~2.0GB（hidden_dim=128, num_layers=9, num_blocks=1）
  - 优化器状态（如果有）：~0.5GB
  - 模型结构：~0.1GB
- **CPU**: 中（10-20%），单核，约2-5秒
  - 文件I/O：读取检查点文件
  - 反序列化：PyTorch权重加载
- **时间**: 2-5秒

### 1.3 特征转换器初始化
- **显存**: < 0.1GB
- **CPU**: 低（< 5%），约0.1秒
- **操作**: 创建特征化器对象

### 1.4 数据集加载
- **显存**: 0.2-0.5GB（数据缓存，如果启用）
- **CPU**: 中（15-30%），多核，约3-10秒
  - 文件I/O：读取数据集文件
  - 数据预处理：特征提取、图构建
  - 单核瓶颈：主要在数据解析
- **时间**: 3-10秒（取决于数据集大小）

### 1.5 模型实例化
- **显存**: +0.2GB（模型结构）
- **CPU**: 低（< 10%），约0.5-1秒
- **时间**: 0.5-1秒

**初始化阶段总计**:
- **显存**: 2.8-3.5GB
- **CPU**: 平均15-25%（峰值30%）
- **时间**: 6-17秒

---

## 二、动态采样模式（Legacy）

### 2.1 大步探索阶段 (`sample_diffusion_large_step`)

#### 配置参数（优化后）
- `batch_size`: 16
- `n_repeat`: 4
- `stride`: 50（时间步间隔）
- 实际时间步数：约10-20步（从1000到500）

#### 显存使用
- **模型权重**: 2.5GB（已加载）
- **批次数据**:
  - 蛋白数据：16 × (150原子 × 3坐标 + 特征) ≈ 0.3GB
  - 配体数据：16 × (30原子 × 3坐标 + 特征) ≈ 0.2GB
  - 图结构（边、索引）：≈ 0.2GB
- **中间激活**:
  - 每层隐藏状态：16 × 30 × 128 × 9层 ≈ 0.7GB
  - 注意力矩阵：16 × 180 × 180 × 16头 ≈ 0.3GB
  - 梯度缓存（如果启用）：≈ 0.5GB
- **轨迹存储**: ≈ 0.3GB
- **峰值显存**: **4.5-6.0GB**

#### CPU使用
- **使用率**: 5-15%（主要在数据转换）
- **核心数**: 1-2核
- **操作**: 
  - 数据格式转换（GPU↔CPU）
  - NumPy数组操作
  - 原子数量采样（CPU计算）

#### 运行时间（RTX 5080 + 14900K）
- **单次大步探索**: 8-15秒
  - 模型前向传播：6-12秒（GPU计算）
  - 数据转换：1-2秒（CPU）
  - 其他开销：1秒
- **4次重复**: **32-60秒**

### 2.2 候选评估阶段 (`evaluate_candidate`)

#### 配置参数
- 候选数量：16 × 4 = 64个
- 每个候选评估：分子重建 + 化学指标计算

#### 显存使用
- **显存**: < 0.5GB（主要在CPU处理）
- **操作**: 数据从GPU转移到CPU

#### CPU使用
- **使用率**: 30-60%（多核并行）
- **核心数**: 4-8核（RDKit并行处理）
- **操作**:
  - 分子重建（OpenBabel）：CPU密集型
  - SMILES转换：CPU计算
  - QED/SA计算：CPU计算
- **每个候选**: 0.1-0.3秒

#### 运行时间
- **64个候选评估**: 6-19秒
  - 分子重建：4-12秒（CPU瓶颈）
  - 化学指标计算：2-7秒

### 2.3 候选筛选 (`select_top_candidates`)

#### 显存使用
- **显存**: < 0.1GB（CPU操作）

#### CPU使用
- **使用率**: < 5%
- **时间**: < 0.1秒（排序操作）

### 2.4 精炼阶段 (`sample_diffusion_refinement`)

#### 配置参数（优化后）
- `top_n`: 12
- `n_sampling`: 2
- 总精炼任务：12 × 2 = 24个
- `stride`: 10（时间步间隔）
- 实际时间步数：约50步（从500到0）

#### 显存使用（单个精炼任务）
- **模型权重**: 2.5GB（共享）
- **单个样本数据**: 0.05-0.1GB
- **中间激活**: 0.3-0.5GB
- **峰值显存**: **2.8-3.5GB**（单任务）

#### CPU使用
- **使用率**: 5-10%
- **核心数**: 1核

#### 运行时间（单个精炼任务）
- **单次精炼**: 5-12秒
  - 模型前向传播：4-10秒（GPU）
  - 数据转换：0.5-1秒（CPU）
  - 其他：0.5-1秒
- **24个任务（串行）**: **120-288秒**（2-5分钟）

**动态采样（Legacy）总计**:
- **峰值显存**: 6.0GB（大步阶段）
- **平均显存**: 3-4GB
- **CPU使用**: 平均20-30%（峰值60%在评估阶段）
- **总时间**: **158-367秒**（约2.5-6分钟，生成12个精炼样本）

---

## 三、统一动态采样模式（Unified）

### 配置参数
- `num_samples`: 100（逐个生成）
- `num_steps`: 1000（完整扩散过程）

### 3.1 单样本生成循环

#### 显存使用（单个样本）
- **模型权重**: 2.5GB
- **单样本数据**: 0.05-0.1GB
- **中间激活**: 0.3-0.5GB
- **轨迹存储**: 0.1-0.2GB
- **峰值显存**: **2.9-3.3GB**

#### CPU使用
- **使用率**: 5-10%
- **核心数**: 1核

#### 运行时间（单个样本）
- **单样本生成**: 15-30秒
  - 大步阶段：8-15秒
  - 精炼阶段：7-15秒
- **100个样本**: **1500-3000秒**（25-50分钟）

**统一动态采样总计**:
- **峰值显存**: 3.3GB
- **平均显存**: 3.0GB
- **CPU使用**: 平均5-10%
- **总时间**: **25-50分钟**（100个样本）

---

## 四、基线采样模式（Baseline）

### 配置参数（优化后）
- `batch_size`: 32
- `num_samples`: 100
- `num_steps`: 1000
- 批次数：ceil(100/32) = 4批

### 4.1 批次处理

#### 显存使用（单批次）
- **模型权重**: 2.5GB
- **批次数据**:
  - 蛋白：32 × 150原子 ≈ 0.6GB
  - 配体：32 × 30原子 ≈ 0.3GB
  - 图结构：≈ 0.3GB
- **中间激活**:
  - 隐藏状态：32 × 30 × 128 × 9 ≈ 1.4GB
  - 注意力矩阵：32 × 180 × 180 × 16 ≈ 0.6GB
  - 轨迹存储：≈ 0.5GB
- **峰值显存**: **6.0-7.5GB**

#### CPU使用
- **使用率**: 5-15%
- **核心数**: 1-2核

#### 运行时间（单批次）
- **单批次（32样本）**: 40-90秒
  - 模型前向传播（1000步）：35-80秒（GPU）
  - 数据转换：3-7秒（CPU）
  - 轨迹拆分：2-3秒（CPU）
- **4批次**: **160-360秒**（约2.5-6分钟）

**基线采样总计**:
- **峰值显存**: 7.5GB
- **平均显存**: 6-7GB
- **CPU使用**: 平均10-15%
- **总时间**: **2.5-6分钟**（100个样本）

---

## 五、结果保存阶段

### 显存使用
- **显存**: +0.5-1.0GB（临时，保存后释放）
- **操作**: 数据从GPU转移到CPU，序列化

### CPU使用
- **使用率**: 10-20%
- **时间**: 2-5秒（取决于结果大小）

---

## 六、资源使用总结表

| 阶段 | 显存峰值 (GB) | CPU平均 (%) | CPU峰值 (%) | 时间 (秒) | 备注 |
|------|--------------|-------------|-------------|-----------|------|
| **初始化** | 3.5 | 15-25 | 30 | 6-17 | 一次性 |
| **动态采样-大步** | 6.0 | 5-15 | 20 | 32-60 | 4次重复 |
| **动态采样-评估** | 0.5 | 30-60 | 80 | 6-19 | CPU密集型 |
| **动态采样-精炼** | 3.5 | 5-10 | 15 | 120-288 | 24个任务 |
| **动态采样-总计** | 6.0 | 20-30 | 80 | **158-367** | 12个样本 |
| **统一动态-单样本** | 3.3 | 5-10 | 15 | 15-30 | 逐个生成 |
| **统一动态-100样本** | 3.3 | 5-10 | 15 | **1500-3000** | 25-50分钟 |
| **基线采样-单批次** | 7.5 | 10-15 | 20 | 40-90 | 32样本/批 |
| **基线采样-100样本** | 7.5 | 10-15 | 20 | **160-360** | 2.5-6分钟 |

---

## 七、性能优化建议

### 7.1 显存优化
1. **使用梯度检查点**（如果支持）：减少中间激活显存
2. **及时释放中间变量**：使用 `del` 和 `torch.cuda.empty_cache()`
3. **分批处理评估**：避免一次性评估所有候选

### 7.2 CPU优化
1. **并行评估**：使用多进程处理候选评估（RDKit支持）
2. **数据预处理缓存**：缓存预处理结果
3. **减少CPU-GPU数据传输**：尽量在GPU上完成计算

### 7.3 时间优化
1. **减少扩散步数**：如果质量可接受，减少 `num_steps`
2. **使用混合精度**：FP16可以加速2倍（如果模型支持）
3. **批量评估**：优化候选评估的批处理

---

## 八、实际运行时间估算（14900K + RTX 5080）

### 场景1：动态采样，生成12个精炼样本
- **总时间**: 2.5-6分钟
- **显存峰值**: 6.0GB
- **CPU平均**: 25%

### 场景2：统一动态采样，生成100个样本
- **总时间**: 25-50分钟
- **显存峰值**: 3.3GB
- **CPU平均**: 8%

### 场景3：基线采样，生成100个样本
- **总时间**: 2.5-6分钟
- **显存峰值**: 7.5GB
- **CPU平均**: 12%

**推荐配置**（16GB显存）:
- **动态采样**: 适合生成高质量样本，时间较长
- **基线采样**: 适合快速生成大量样本，显存需求较高

